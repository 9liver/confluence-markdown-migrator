"""Index generator for creating README.md navigation files."""

import logging
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from models import ConfluenceSpace, ConfluencePage

logger = logging.getLogger('confluence_markdown_migrator.exporters.index_generator')


class IndexGenerator:
    """
    Generates README.md navigation files for Confluence spaces.
    
    This generator:
    1. Creates hierarchical table of contents from page structure
    2. Includes space metadata and statistics
    3. Adds navigation links and warnings for problematic pages
    4. Creates valid markdown compatible with GitHub, Wiki.js, BookStack
    """
    
    def __init__(self, logger: Optional[logging.Logger] = None):
        """
        Initialize the index generator.
        
        Args:
            logger: Logger instance
        """
        self.logger = logger or logging.getLogger('confluence_markdown_migrator.exporters.index_generator')
    
    def generate_space_index(self, space: ConfluenceSpace, space_dir: Path) -> Path:
        """
        Generate README.md index file for a Confluence space.
        
        Args:
            space: ConfluenceSpace instance
            space_dir: Space output directory
            
        Returns:
            Path to created README.md file
        """
        self.logger.debug(f"Generating index for space '{space.key}'")
        
        # Build index content
        content = []
        
        # Frontmatter
        content.append("---")
        content.append(f"confluence_space_key: {space.key}")
        content.append(f"space_name: {space.name}")
        
        if space.description:
            content.append(f"description: {space.description}")
        
        # Statistics
        page_count = len(space.pages) + sum(
            len(page.get_all_descendants()) for page in space.pages
        )
        content.append(f"page_count: {page_count}")
        
        # Count attachments
        attachment_count = sum(
            len(page.attachments) for page in space.get_all_pages()
        )
        content.append(f"attachment_count: {attachment_count}")
        
        # Add generation timestamp
        content.append(f"generated_at: {datetime.utcnow().isoformat()}")
        content.append("---")
        content.append("")
        
        # Title
        content.append(f"# {space.name}")
        content.append("")
        
        # Space description
        if space.description:
            content.append(space.description)
            content.append("")
        
        # Statistics section
        content.append("## ðŸ“Š Space Statistics")
        content.append("")
        content.append(f"- **Total Pages:** {page_count}")
        content.append(f"- **Root Pages:** {len(space.pages)}")
        content.append(f"- **Total Attachments:** {attachment_count}")
        
        # Conversion status summary
        conversion_summary = self._get_conversion_summary(space)
        if conversion_summary:
            content.append(f"- **Conversion Status:** {conversion_summary}")
        
        content.append("")
        
        # Table of Contents
        if space.pages:
            content.append("## ðŸ“š Table of Contents")
            content.append("")
            
            # Generate TOC from page hierarchy
            toc = self._generate_toc(space.pages, space.key, depth=0)
            content.extend(toc)
            content.append("")
        
        # Warnings section
        warnings = self._collect_warnings(space)
        if warnings:
            content.append("## âš ï¸ Conversion Warnings")
            content.append("")
            for warning in warnings[:10]:  # Limit to first 10 warnings
                content.append(f"- âš ï¸ {warning}")
            if len(warnings) > 10:
                content.append(f"- ... and {len(warnings) - 10} more warnings")
            content.append("")
        
        # Footer
        content.append("---")
        content.append("*Generated by Confluence Markdown Migrator*")
        content.append(f"*Export Date: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S UTC')}*")
        
        # Write file
        readme_path = space_dir / "README.md"
        readme_path.write_text('\n'.join(content), encoding='utf-8')
        
        self.logger.info(f"Generated index: {readme_path}")
        return readme_path
    
    def _generate_toc(self, pages: List[ConfluencePage], space_key: str, depth: int = 0) -> List[str]:
        """
        Generate hierarchical table of contents from pages.
        
        Args:
            pages: List of ConfluencePage instances
            depth: Current depth level
            
        Returns:
            List of markdown lines for TOC
        """
        toc_lines = []
        
        for page in pages:
            # Calculate relative path
            page_path = self._calculate_page_path(page)
            if not page_path:
                continue
            
            # Indentation based on depth
            indent = "  " * depth
            
            # Page title (with status indicator if needed)
            title = page.title
            status_prefix = self._get_status_prefix(page)
            if status_prefix:
                title = f"{status_prefix} {title}"
            
            # Add TOC entry
            toc_lines.append(f"{indent}- [{title}]({page_path})")
            
            # Recursively add children
            if page.children:
                child_toc = self._generate_toc(page.children, depth + 1)
                toc_lines.extend(child_toc)
        
        return toc_lines
    
    def _calculate_page_path(self, page: ConfluencePage) -> Optional[str]:
        """
        Calculate relative path to page markdown file.
        
        Args:
            page: ConfluencePage instance
            
        Returns:
            Relative path or None if not available
        """
        # Check if export metadata exists
        export_metadata = page.conversion_metadata.get('export_metadata', {})
        exported_path = export_metadata.get('exported_path')
        
        if exported_path:
            return exported_path
        
        # Fallback: generate path from title
        if page.title:
            sanitized = self._sanitize_filename(page.title)
            # Assume leaf page for simplicity
            return f"./{sanitized}.md"
        
        return None
    
    def _sanitize_filename(self, title: str) -> str:
        """
        Convert page title to filesystem-safe filename.
        
        Args:
            title: Page title
            
        Returns:
            Sanitized filename
        """
        if not title:
            return "untitled"
        
        # Convert to lowercase
        sanitized = title.lower()
        
        # Replace special characters with hyphens
        import re
        sanitized = re.sub(r'[^a-z0-9\-_]', '-', sanitized)
        
        # Remove consecutive hyphens
        sanitized = re.sub(r'-+', '-', sanitized)
        
        # Remove leading/trailing hyphens
        sanitized = sanitized.strip('-')
        
        # Truncate
        if len(sanitized) > 100:
            sanitized = sanitized[:100]
        
        return sanitized or "untitled"
    
    def _get_status_prefix(self, page: ConfluencePage) -> Optional[str]:
        """
        Get status indicator prefix for page.
        
        Args:
            page: ConfluencePage instance
            
        Returns:
            Status emoji or None
        """
        status = page.conversion_metadata.get('conversion_status', 'pending')
        
        if status == 'failed':
            return "âŒ"
        elif status == 'partial':
            return "âš ï¸"
        elif not page.markdown_content:
            return "âš ï¸"
        
        return None
    
    def _get_conversion_summary(self, space: ConfluenceSpace) -> Optional[str]:
        """
        Generate conversion status summary for space.
        
        Args:
            space: ConfluenceSpace instance
            
        Returns:
            Status summary string or None
        """
        all_pages = space.get_all_pages()
        if not all_pages:
            return None
        
        total = len(all_pages)
        success = 0
        partial = 0
        failed = 0
        pending = 0
        
        for page in all_pages:
            status = page.conversion_metadata.get('conversion_status', 'pending')
            if not page.markdown_content:
                failed += 1
            elif status == 'success':
                success += 1
            elif status == 'partial':
                partial += 1
            elif status == 'failed':
                failed += 1
            else:
                pending += 1
        
        if success == total:
            return f"âœ… All {total} pages converted successfully"
        elif failed == total:
            return f"âŒ All {total} pages failed conversion"
        else:
            parts = []
            if success > 0:
                parts.append(f"{success} âœ…")
            if partial > 0:
                parts.append(f"{partial} âš ï¸")
            if failed > 0:
                parts.append(f"{failed} âŒ")
            if pending > 0:
                parts.append(f"{pending} â³")
            
            return f"{total} pages: {', '.join(parts)}"
    
    def _collect_warnings(self, space: ConfluenceSpace) -> List[str]:
        """
        Collect warnings for problematic pages.
        
        Args:
            space: ConfluenceSpace instance
            
        Returns:
            List of warning messages
        """
        warnings = []
        
        for page in space.get_all_pages():
            # Check for pages without markdown content
            if not page.markdown_content:
                warnings.append(
                    f"Page '{page.title}' (ID: {page.id}) has no markdown content"
                )
            
            # Check for conversion errors
            export_errors = page.conversion_metadata.get('export_errors', [])
            if export_errors:
                warnings.append(
                    f"Page '{page.title}' export errors: {', '.join(export_errors[:3])}"
                )
            
            # Check for broken links
            broken_links = page.conversion_metadata.get('broken_links', [])
            if broken_links:
                warnings.append(
                    f"Page '{page.title}' has {len(broken_links)} broken links"
                )
            
            # Check conversion status
            status = page.conversion_metadata.get('conversion_status', 'pending')
            if status == 'failed':
                warnings.append(
                    f"Page '{page.title}' conversion failed"
                )
            elif status == 'partial':
                warnings.append(
                    f"Page '{page.title}' conversion partially successful"
                )
        
        return warnings